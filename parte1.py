# -*- coding: utf-8 -*-
"""parte1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vn9tq-1MEvpJks2XlWa0ZJB6gtCvRqNh
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# ===============================================
# 1. CARGA DE DATOS
# ===============================================
df = pd.read_csv("unificado.csv")

# ===============================================
# 2. LIMPIEZA Y PREPARACI√ìN DE DATOS
# ===============================================
# Reemplazar los valores 999 y 9999 por NaN ya que suelen representar valores perdidos
df.replace({999: np.nan, 9999: np.nan}, inplace=True)

# Separar las variables num√©ricas y categ√≥ricas
numericas = df.select_dtypes(include=[np.number])
categoricas = df.select_dtypes(exclude=[np.number])

# ===============================================
# 3. AN√ÅLISIS DESCRIPTIVO DE VARIABLES NUM√âRICAS
# ===============================================
# Calcular estad√≠sticas como media, desviaci√≥n est√°ndar, min, max, etc.
desc_stats = numericas.describe().T

# Agregar medidas de forma de la distribuci√≥n
desc_stats["skewness"] = numericas.skew()      # Asimetr√≠a
desc_stats["kurtosis"] = numericas.kurtosis()  # Curtosis

# Mostrar resumen estad√≠stico completo
display(desc_stats)

# ===============================================
# 4. VISUALIZACI√ìN: HISTOGRAMAS Y BOXPLOTS
# ===============================================
# Crear histogramas y diagramas de caja para cada variable num√©rica
for col in numericas.columns:
    plt.figure(figsize=(14, 5))

    # Histograma con curva de densidad
    plt.subplot(1, 2, 1)
    sns.histplot(numericas[col].dropna(), kde=True, bins=30)
    plt.title(f"Histograma: {col}")

    # Diagrama de caja (boxplot) para ver outliers
    plt.subplot(1, 2, 2)
    sns.boxplot(x=numericas[col])
    plt.title(f"Boxplot: {col}")

    plt.tight_layout()
    plt.show()

# ===============================================
# 5. MATRIZ DE CORRELACI√ìN ENTRE VARIABLES NUM√âRICAS
# ===============================================
# Visualizar c√≥mo se relacionan las variables entre s√≠
plt.figure(figsize=(12, 8))
sns.heatmap(numericas.corr(), annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Matriz de correlaci√≥n")
plt.show()

# ===============================================
# 6. TRATAMIENTO DE VALORES FALTANTES
# ===============================================
# Imputar valores faltantes usando la media de cada variable
imputer = SimpleImputer(strategy="mean")
numericas_imputadas = pd.DataFrame(imputer.fit_transform(numericas), columns=numericas.columns)

# ===============================================
# 7. DETECCI√ìN DE OUTLIERS CON M√âTODO IQR
# ===============================================
outliers_info = {}
for col in numericas.columns:
    q1 = numericas[col].quantile(0.25)
    q3 = numericas[col].quantile(0.75)
    iqr = q3 - q1
    lower = q1 - 1.5 * iqr
    upper = q3 + 1.5 * iqr
    outliers = ((numericas[col] < lower) | (numericas[col] > upper)).sum()
    outliers_info[col] = outliers

# Mostrar cantidad de outliers por variable
df_outliers = pd.DataFrame.from_dict(outliers_info, orient='index', columns=['Outliers'])
display(df_outliers)

# ===============================
# RELACIONES ENTRE VARIABLES
# ===============================

print("üìå An√°lisis de relaciones entre variables num√©ricas:\n")
# Ya se visualiz√≥ la matriz de correlaci√≥n, pero ahora se puede complementar con pares espec√≠ficos:
top_corr = numericas.corr().unstack().sort_values(ascending=False)
top_corr = top_corr[(top_corr < 1) & (top_corr > 0.5)].drop_duplicates()
print("üîç Pares de variables num√©ricas con alta correlaci√≥n (> 0.5):")
display(top_corr)

# Relaci√≥n entre edad y escolaridad
plt.figure(figsize=(6, 5))
sns.scatterplot(data=df, x="EDADHOM", y="ESCHOM", alpha=0.3)
plt.title("Relaci√≥n entre Edad y Escolaridad (Hombres)")
plt.show()

plt.figure(figsize=(6, 5))
sns.scatterplot(data=df, x="EDADMUJ", y="ESCMUJ", alpha=0.3)
plt.title("Relaci√≥n entre Edad y Escolaridad (Mujeres)")
plt.show()

# Cruce entre ocupaci√≥n y escolaridad
print("üìå Distribuci√≥n de escolaridad por ocupaci√≥n del hombre:")
cross1 = pd.crosstab(df["CIUOHOM"], df["ESCHOM"])
display(cross1)

print("üìå Distribuci√≥n de escolaridad por ocupaci√≥n de la mujer:")
cross2 = pd.crosstab(df["CIUOMUJ"], df["ESCMUJ"])
display(cross2)

# Opcional: heatmap para visualizar cruce
plt.figure(figsize=(10, 6))
sns.heatmap(cross1, cmap="YlGnBu", cbar_kws={'label': 'Frecuencia'})
plt.title("Heatmap: Escolaridad vs Ocupaci√≥n (Hombres)")
plt.ylabel("Ocupaci√≥n (CIUOHOM)")
plt.xlabel("Escolaridad")
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
sns.heatmap(cross2, cmap="YlGnBu", cbar_kws={'label': 'Frecuencia'})
plt.title("Heatmap: Escolaridad vs Ocupaci√≥n (Mujeres)")
plt.ylabel("Ocupaci√≥n (CIUOMUJ)")
plt.xlabel("Escolaridad")
plt.tight_layout()
plt.show()


print(f"8. AN√ÅLISIS DE VARIABLES CATEG√ìRICAS")

# ===============================================
# 8. AN√ÅLISIS DE VARIABLES CATEG√ìRICAS
# ===============================================
# Para cada variable categ√≥rica:
# - Mostrar frecuencia absoluta
# - Mostrar proporciones relativas
# - Generar gr√°fico de barras
for col in categoricas.columns:
    print(f"\nüî∏ {col} - Frecuencia absoluta:")
    display(df[col].value_counts(dropna=False).rename("Frecuencia").reset_index().rename(columns={"index": col}))

    print(f"\nüî∏ {col} - Proporciones:")
    display(df[col].value_counts(normalize=True, dropna=False).rename("Proporci√≥n").reset_index().rename(columns={"index": col}))

    plt.figure(figsize=(8, 4))
    df[col].value_counts(dropna=False).plot(kind="bar", color="coral")
    plt.title(f"Gr√°fico de barras - {col}")
    plt.ylabel("Frecuencia")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# ===============================================
# 9. AN√ÅLISIS DE AGRUPAMIENTO (CLUSTERING)
# ===============================================
# Estandarizar las variables num√©ricas
scaler = StandardScaler()
X_scaled = scaler.fit_transform(numericas_imputadas)

# Evaluar varios valores de k (n√∫mero de clusters) usando silhouette score
silhouette_scores = []
for k in range(2, 10):
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X_scaled)
    score = silhouette_score(X_scaled, labels)
    silhouette_scores.append(score)

# Visualizar los scores para elegir mejor k
plt.figure(figsize=(8, 4))
plt.plot(range(2, 10), silhouette_scores, marker='o', color='purple')
plt.title("Silhouette Score vs N√∫mero de Clusters")
plt.xlabel("Clusters")
plt.ylabel("Silhouette Score")
plt.grid(True)
plt.show()

# Imprimir el mejor n√∫mero de clusters encontrado
mejor_k = np.argmax(silhouette_scores) + 2
print(f"‚úÖ Mejor n√∫mero de clusters: {mejor_k}")